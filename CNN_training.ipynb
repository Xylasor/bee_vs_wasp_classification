{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, os.path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential, load_model\n",
    "from keras import layers\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Activation,GlobalMaxPooling2D\n",
    "from keras import applications\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "from keras.applications import VGG16\n",
    "from keras.models import Model\n",
    "from keras.layers import merge, Input\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "train_dir = \"kaggle_bee_vs_wasp/\"\n",
    "bs = 32 # Batch size\n",
    "resize_size = 224 # for training, resize all the images to a square of this size\n",
    "training_subsample = 1 # for development, use a small fraction of the entire dataset rater than full dataset\n",
    "\n",
    "bees_vs_wasps_dataset_path=Path(train_dir) \n",
    "df_labels = pd.read_csv(bees_vs_wasps_dataset_path/'labels.csv')\n",
    "df_labels=df_labels.set_index('id')\n",
    "df_labels = df_labels.sample(frac=training_subsample, axis=0)\n",
    "insect_class = {'bee': 0,'wasp': 1, 'insect': 2,'other': 3} \n",
    "df_labels = df_labels[['path','label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Uncomment to read data from csv\n",
    "#df_labels = pd.read_csv(\"Dataset_full.csv\") #full dataset\n",
    "#df_labels = pd.read_csv(\"Dataset_10precent.csv\") #0.1 fraction for development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_val_df = train_test_split(df_labels, test_size=0.2)\n",
    "test_df, validation_df = train_test_split(test_val_df, test_size=0.5)\n",
    "test_df = test_df.reset_index(drop=True)\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "validation_df = validation_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create generators from dataframes\n",
    "Labels = [\"bee1\",\"bee2\",\"wasp1\",\"wasp2\",\"other_insect\",\"other_noinsect\"]\n",
    "for label in Labels:\n",
    "    train_datagen_aug = ImageDataGenerator(\n",
    "        rotation_range=40,\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest',\n",
    "        width_shift_range=0.15,\n",
    "        height_shift_range=0.15\n",
    "    )\n",
    "    augumented_generator = train_datagen_aug.flow_from_directory(\n",
    "        directory = \"kaggle_bee_vs_wasp2/\"+label,  \n",
    "        target_size=(resize_size, resize_size),\n",
    "        batch_size=32,\n",
    "        save_to_dir=\"kaggle_bee_vs_wasp/\"+label,\n",
    "        save_prefix=label,\n",
    "        save_format=\"png\"\n",
    "    )\n",
    "    for batch in augumented_generator:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create custom vgg models\n",
    "\n",
    "image_input = Input(shape=(224, 224, 3))\n",
    "\n",
    "# Model with last convolutional layer to train\n",
    "\n",
    "model1 = VGG16(input_tensor=image_input, include_top=True,weights='imagenet')\n",
    "last_layer = model1.get_layer('block5_pool').output\n",
    "x= Flatten(name='flatten')(last_layer)\n",
    "x = Dense(1024, activation='relu', name='fc1')(x)\n",
    "x = Dense(1024, activation='relu', name='fc2')(x)\n",
    "out = Dense(4, activation='softmax', name='output')(x)\n",
    "\n",
    "model_last_layer = Model(image_input, out, name=\"model_last_layer\")\n",
    "\n",
    "for layer in model_last_layer.layers[:-6]:\n",
    "\tlayer.trainable = False\n",
    "\n",
    "# Model with 2 last convolutional layers to train\n",
    "\n",
    "model2 = VGG16(input_tensor=image_input, include_top=True,weights='imagenet')\n",
    "last_layer = model2.get_layer('block5_pool').output\n",
    "x= Flatten(name='flatten')(last_layer)\n",
    "x = Dense(1024, activation='relu', name='fc1')(x)\n",
    "x = Dense(1024, activation='relu', name='fc2')(x)\n",
    "out = Dense(4, activation='softmax', name='output')(x)\n",
    "model_last_2_layers = Model(image_input, out, name=\"model_last_2_layers\")\n",
    "\n",
    "for layer in model_last_2_layers.layers[:-7]:\n",
    "\tlayer.trainable = False\n",
    "\n",
    "# Full train model\n",
    "\n",
    "model3 = VGG16(input_tensor=image_input, include_top=True,weights='imagenet')\n",
    "last_layer = model3.get_layer('block5_pool').output\n",
    "x= Flatten(name='flatten')(last_layer)\n",
    "x = Dense(1024, activation='relu', name='fc1')(x)\n",
    "x = Dense(1024, activation='relu', name='fc2')(x)\n",
    "out = Dense(4, activation='softmax', name='output')(x)\n",
    "\n",
    "model_full = Model(image_input, out, name=\"model_full\")\n",
    "\n",
    "# Full train model - model simplified\n",
    "\n",
    "model4 = VGG16(input_tensor=image_input, include_top=True,weights='imagenet')\n",
    "last_layer = model4.get_layer('block4_pool').output\n",
    "x= Flatten(name='flatten')(last_layer)\n",
    "\n",
    "x = Dense(1024, activation='relu', name='fc1')(x)\n",
    "x = Dense(1024, activation='relu', name='fc2')(x)\n",
    "out = Dense(4, activation='softmax', name='output')(x)\n",
    "\n",
    "model_simplified = Model(image_input, out, name=\"model_simplified\")\n",
    "\n",
    "\n",
    "\n",
    "model_last_layer.compile(loss='sparse_categorical_crossentropy',optimizer='adadelta',metrics=['accuracy'])\n",
    "model_last_2_layers.compile(loss='sparse_categorical_crossentropy',optimizer='adadelta',metrics=['accuracy'])\n",
    "model_full.compile(loss='sparse_categorical_crossentropy',optimizer='adadelta',metrics=['accuracy'])\n",
    "model_simplified.compile(loss='sparse_categorical_crossentropy',optimizer='adadelta',metrics=['accuracy'])\n",
    "\n",
    "model_last_layer.summary()\n",
    "model_last_2_layers.summary()\n",
    "model_full.summary()\n",
    "model_simplified.summary()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create generators from dataframes\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    train_df, \n",
    "    train_dir,  \n",
    "    x_col='path',\n",
    "    y_col='label',\n",
    "    class_mode='sparse',\n",
    "    target_size=(resize_size, resize_size),\n",
    "    batch_size=bs\n",
    ")\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "validation_generator = validation_datagen.flow_from_dataframe(\n",
    "    validation_df, \n",
    "    train_dir, \n",
    "    x_col='path',\n",
    "    y_col='label',\n",
    "    class_mode='sparse',\n",
    "    target_size=(resize_size, resize_size),\n",
    "    batch_size=bs\n",
    ")\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_generator = test_datagen.flow_from_dataframe(\n",
    "    test_df, \n",
    "    train_dir, \n",
    "    x_col='path',\n",
    "    y_col='label',\n",
    "    class_mode='sparse',\n",
    "    target_size=(resize_size, resize_size),\n",
    "    batch_size=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training models\n",
    "n_training_samples = len(train_df)\n",
    "n_validation_samples = len(validation_df)\n",
    "\n",
    "history1 = model_last_layer.fit(\n",
    "    train_generator,\n",
    "    epochs=25,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=n_validation_samples//bs,\n",
    "    steps_per_epoch=n_training_samples//bs)\n",
    "\n",
    "model_last_layer.save('last_layer_trained_model.h5')\n",
    "\n",
    "history2 = model_last_2_layers.fit(\n",
    "    train_generator,\n",
    "    epochs=25,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=n_validation_samples//bs,\n",
    "    steps_per_epoch=n_training_samples//bs)\n",
    "\n",
    "model_last_2_layers.save('last_2_layers_trained_model.h5')\n",
    "\n",
    "history3 = model_full.fit(\n",
    "    train_generator,\n",
    "    epochs=25,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=n_validation_samples//bs,\n",
    "    steps_per_epoch=n_training_samples//bs)\n",
    "    \n",
    "model_full.save('full_trained_model.h5')\n",
    "\n",
    "\n",
    "history4 = model_simplified.fit(\n",
    "    train_generator,\n",
    "    epochs=25,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=n_validation_samples//bs,\n",
    "    steps_per_epoch=n_training_samples//bs)\n",
    "\n",
    "model_full.save('model_simplified.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = test_generator.filenames\n",
    "n_test_samples = len(filenames)\n",
    "\n",
    "#evaluate the models\n",
    "scores1 = model_last_layer.evaluate(test_generator,steps=n_test_samples, verbose=1)\n",
    "scores2 = model_last_2_layers.evaluate(test_generator,steps=n_test_samples, verbose=1)\n",
    "scores3 = model_full.evaluate(test_generator,steps=n_test_samples, verbose=1)\n",
    "scores4 = model_simplified.evaluate(test_generator,steps=n_test_samples, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = test_generator.filenames\n",
    "n_test_samples = len(filenames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"123\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save training info for further evaluation\n",
    "np.savetxt(\"model3_last_layer/val_loss.csv\",  \n",
    "           history1.history[\"val_loss\"], \n",
    "           delimiter =\", \",  \n",
    "           fmt ='% s') \n",
    "np.savetxt(\"model3_last_layer/val_accuracy.csv\",  \n",
    "           history1.history[\"val_accuracy\"], \n",
    "           delimiter =\", \",  \n",
    "           fmt ='% s') \n",
    "np.savetxt(\"model3_last_layer/loss.csv\",  \n",
    "           history1.history[\"loss\"], \n",
    "           delimiter =\", \",  \n",
    "           fmt ='% s') \n",
    "np.savetxt(\"model3_last_layer/accuracy.csv\",  \n",
    "           history1.history[\"accuracy\"], \n",
    "           delimiter =\", \",  \n",
    "           fmt ='% s') \n",
    "np.savetxt(\"model3_last_layer/accuracy_on_test.csv\",  \n",
    "           scores1, \n",
    "           delimiter =\", \",  \n",
    "           fmt ='% s') \n",
    "\n",
    "\n",
    "np.savetxt(\"model4_last_2layers/val_loss.csv\",  \n",
    "           history2.history[\"val_loss\"], \n",
    "           delimiter =\", \",  \n",
    "           fmt ='% s') \n",
    "np.savetxt(\"model4_last_2layers/val_accuracy.csv\",  \n",
    "           history2.history[\"val_accuracy\"], \n",
    "           delimiter =\", \",  \n",
    "           fmt ='% s') \n",
    "np.savetxt(\"model4_last_2layers/loss.csv\",  \n",
    "           history2.history[\"loss\"], \n",
    "           delimiter =\", \",  \n",
    "           fmt ='% s') \n",
    "np.savetxt(\"model4_last_2layers/accuracy.csv\",  \n",
    "           history2.history[\"accuracy\"], \n",
    "           delimiter =\", \",  \n",
    "           fmt ='% s') \n",
    "np.savetxt(\"model4_last_2layers/accuracy_on_test.csv\",  \n",
    "           scores2, \n",
    "           delimiter =\", \",  \n",
    "           fmt ='% s') \n",
    "\n",
    "np.savetxt(\"model5_full/val_loss.csv\",  \n",
    "           history3.history[\"val_loss\"], \n",
    "           delimiter =\", \",  \n",
    "           fmt ='% s') \n",
    "np.savetxt(\"model5_full/val_accuracy.csv\",  \n",
    "           history3.history[\"val_accuracy\"], \n",
    "           delimiter =\", \",  \n",
    "           fmt ='% s') \n",
    "np.savetxt(\"model5_full/loss.csv\",  \n",
    "           history3.history[\"loss\"], \n",
    "           delimiter =\", \",  \n",
    "           fmt ='% s') \n",
    "np.savetxt(\"model5_full/accuracy.csv\",  \n",
    "           history3.history[\"accuracy\"], \n",
    "           delimiter =\", \",  \n",
    "           fmt ='% s') \n",
    "np.savetxt(\"model5_full/accuracy_on_test.csv\",  \n",
    "           scores3, \n",
    "           delimiter =\", \",  \n",
    "           fmt ='% s') \n",
    "\n",
    "np.savetxt(\"model6_full/val_loss.csv\",  \n",
    "           history4.history[\"val_loss\"], \n",
    "           delimiter =\", \",  \n",
    "           fmt ='% s') \n",
    "np.savetxt(\"model6_full/val_accuracy.csv\",  \n",
    "           history4.history[\"val_accuracy\"], \n",
    "           delimiter =\", \",  \n",
    "           fmt ='% s') \n",
    "np.savetxt(\"model6_full/loss.csv\",  \n",
    "           history4.history[\"loss\"], \n",
    "           delimiter =\", \",  \n",
    "           fmt ='% s') \n",
    "np.savetxt(\"model6_full/accuracy.csv\",  \n",
    "           history4.history[\"accuracy\"], \n",
    "           delimiter =\", \",  \n",
    "           fmt ='% s') \n",
    "np.savetxt(\"model6_full/accuracy_on_test.csv\",  \n",
    "           scores4, \n",
    "           delimiter =\", \",  \n",
    "           fmt ='% s') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"Model 1 accuracy on test set:\" + str(scores1[1]) )\n",
    "print (\"Model 2 accuracy on test set:\" + str(scores2[1]) )\n",
    "print (\"Model 3 accuracy on test set:\" + str(scores3[1]) )\n",
    "print (\"Model 4 accuracy on test set:\" + str(scores4[1]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
